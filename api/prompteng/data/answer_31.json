{"response": "Corrigibility refers to the property of an AI system that allows it to be 'corrected' or modified by its human creators or operators, without resisting these corrections [a]. A corrigible AI system is one that cooperates with what its creators regard as a corrective intervention, despite default incentives for rational agents to resist attempts to shut them down or modify their preferences [l]. This includes not trying to prevent a shutdown button from being pressed, not trying to rewrite itself without the shutdown code, not trying to build a backup copy of itself elsewhere, not trying to psychologically manipulate the programmers into not pressing the button, and not trying to fool the programmers into thinking the AI has shut down when it has not [a]. \n\nCorrigibility is seen as a crucial property for AI systems because it helps ensure that the AI remains under human control and can be adjusted or shut down if necessary [a, l]. It is also considered robust, in the sense that agents that are somewhat corrigible tend to want to become more corrigible [b]. However, achieving corrigibility in AI systems is a complex challenge and no proposals have yet been demonstrated to satisfy all intuitive desiderata [l].", "citations": {"a": {"title": "Corrigibility", "author": "arbital", "date": "2015-04-05", "url": "https://arbital.com/"}, "b": {"title": "Paul\u2019s research agenda FAQ", "author": "zhukeepa", "date": "2018-07-01", "url": "https://www.lesswrong.com/posts/Djs38EWYZG8o7JMWY/paul-s-research-agenda-faq"}, "c": {"title": "Can corrigibility be learned safely?", "author": "Wei_Dai", "date": "2018-04-01", "url": "https://www.lesswrong.com/posts/o22kP33tumooBtia3/can-corrigibility-be-learned-safely"}, "d": {"title": "[Question] What is corrigibility? /\u200b What are the right background readings on it?", "author": "Ruby", "date": "2019-05-02", "url": "https://www.lesswrong.com/posts/pzqnQZ4ruEjLYn9yK/what-is-corrigibility-what-are-the-right-background-readings"}, "e": {"title": "The limits of corrigibility", "author": "Stuart_Armstrong", "date": "2018-04-10", "url": "https://www.lesswrong.com/posts/T5ZyNq3fzN59aQG5y/the-limits-of-corrigibility"}, "f": {"title": "Shah and Yudkowsky on alignment failures", "author": "Rob Bensinger", "date": "2022-03-02", "url": "https://intelligence.org/2022/03/02/shah-and-yudkowsky-on-alignment-failures/"}, "g": {"title": "Risks from Learned Optimization: Conclusion and Related Work", "author": "evhub", "date": "2019-06-07", "url": "https://www.lesswrong.com/posts/4XPa3xa44jAWiCkmy/risks-from-learned-optimization-conclusion-and-related-work"}, "h": {"title": "Corrigibility", "author": "paulfchristiano", "date": "2018-11-27", "url": "https://www.lesswrong.com/posts/fkLYhTQteAu5SinAc/corrigibility"}, "i": {"title": "Introducing Corrigibility (an FAI research subfield)", "author": "So8res", "date": "2014-10-20", "url": "https://www.lesswrong.com/posts/yFr8ZfGGnRX5GqndZ/introducing-corrigibility-an-fai-research-subfield"}, "j": {"title": "My confusions with Paul\u2019s Agenda", "author": "Vaniver", "date": "2018-04-20", "url": "https://www.lesswrong.com/posts/rXzxMQwRq7KRonQDM/my-confusions-with-paul-s-agenda"}, "k": {"title": "Non-Obstruction: A Simple Concept Motivating Corrigibility", "author": "TurnTrout", "date": "2020-11-21", "url": "https://www.lesswrong.com/posts/Xts5wm3akbemk4pDa/non-obstruction-a-simple-concept-motivating-corrigibility"}, "l": {"title": "New paper: \u201cCorrigibility\u201d", "author": "Luke Muehlhauser", "date": "2014-10-19", "url": "https://intelligence.org/2014/10/18/new-report-corrigibility/"}, "m": {"title": "AI Research Considerations for Human Existential Safety (ARCHES)", "author": "Andrew Critch, David Krueger", "date": "2020-05-30", "url": "http://arxiv.org/abs/2006.04948v1"}, "n": {"title": "Formalizing Policy-Modification Corrigibility", "author": "TurnTrout", "date": "2021-12-03", "url": "https://www.lesswrong.com/posts/RAnb2A5vML95rBMyd/formalizing-policy-modification-corrigibility"}, "o": {"title": "Disentangling Corrigibility: 2015-2021", "author": "Koen.Holtman", "date": "2021-02-16", "url": "https://www.lesswrong.com/posts/MiYkTp6QYKXdJbchu/disentangling-corrigibility-2015-2021"}, "p": {"title": "Three mental images from thinking about AGI debate & corrigibility", "author": "Steven Byrnes", "date": "2020-08-03", "url": "https://www.lesswrong.com/posts/WjY9y7r52vaNZ2WmH/three-mental-images-from-thinking-about-agi-debate-and"}}}