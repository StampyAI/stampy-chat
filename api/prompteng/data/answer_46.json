{"response": "Eliezer Yudkowsky is a prominent figure in the field of artificial intelligence (AI) and AI alignment. He is one of the co-founders of the value alignment theory and the founder of the Machine Intelligence Research Institute (MIRI) [a]. His work primarily focuses on the challenges posed by artificial intelligence, particularly in the context of long-term safety and alignment [c, d].\n\nYudkowsky is known for his contributions to decision theory, having invented timeless decision theory and extrapolated volition. He also co-invented the tiling agents problem, which initiated the study of logical decision theory, naturalistic reflection, and adversarial AI safety analysis [a].\n\nIn addition to his theoretical work, Yudkowsky is a prolific writer. He has authored numerous papers and essays on topics such as general intelligence and creating friendly AI [c]. He also runs a popular community blog called LessWrong and is working on a book on rationality based on his writings on the blog [n].\n\nYudkowsky's work extends beyond just AI and rationality. He is also known for his fiction writing [g]. Despite his significant contributions and influence in his field, Yudkowsky has been noted to maintain a sense of humility and humor about his work and public persona [m].", "citations": {"a": {"title": "Eliezer Yudkowsky", "author": "arbital", "date": "2015-09-04", "url": "https://arbital.com/"}, "b": {"title": "Eliezer Yudkowsky Facts", "author": "steven0461", "date": "2009-03-22", "url": "https://www.lesswrong.com/posts/Ndtb22KYBxpBsagpj/eliezer-yudkowsky-facts"}, "c": {"title": "Global Catastrophic Risks", "author": "Bostrom, Nick; Cirkovic, Milan M.; Rees, Martin J., Milan M. \u0106irkovi\u0107", "date": "", "url": ""}, "d": {"title": "Discussion with Eliezer Yudkowsky on AGI interventions", "author": "Rob Bensinger", "date": "2021-11-11", "url": "https://intelligence.org/2021/11/11/discussion-with-eliezer-yudkowsky-on-agi-interventions/"}, "e": {"title": "Shah and Yudkowsky on alignment failures", "author": "Rob Bensinger", "date": "2022-03-02", "url": "https://intelligence.org/2022/03/02/shah-and-yudkowsky-on-alignment-failures/"}, "f": {"title": "Science Saturday - Dreaming of an Artificial Intelligence _ Eliezer Yudkowsky _ ", "author": "Eliezer Yudkowsky, Jaron Lanier", "date": "", "url": ""}, "g": {"title": "John Horgan interviews Eliezer Yudkowsky", "author": "Rob Bensinger", "date": "2016-03-03", "url": "https://intelligence.org/2016/03/02/john-horgan-interviews-eliezer-yudkowsky/"}, "h": {"title": "Eliezer Yudkowsky \u2013 AI Alignment - Why It_s Hard, and Where to Start-by Machine ", "author": "Eliezer Yudkowsky, Question from Audience", "date": "", "url": ""}, "i": {"title": "Shah and Yudkowsky on alignment failures", "author": "Rohin Shah", "date": "2022-02-28", "url": "https://www.lesswrong.com/posts/tcCxPLBrEXdxN5HCQ/shah-and-yudkowsky-on-alignment-failures"}, "j": {"title": "MIRI announces new \"Death With Dignity\" strategy", "author": "Eliezer Yudkowsky", "date": "2022-04-02", "url": "https://www.lesswrong.com/posts/j9Q8bRmwCgXRYAgcJ/miri-announces-new-death-with-dignity-strategy"}, "k": {"title": "Science Saturday - The Great Singularity Debate _ Eliezer Yudkowsky _ Massimo Pi", "author": "Eliezer Yudkowsky, Massimo Pigliucci", "date": "", "url": ""}, "l": {"title": "Yehuda Yudkowsky, 1985-2004", "author": "Eliezer S. Yudkowsky", "date": "2020-09-04", "url": "https://www.yudkowsky.net/other/yehuda"}, "m": {"title": "On Things that are Awesome", "author": "Eliezer Yudkowsky", "date": "2009-03-24", "url": "https://www.lesswrong.com/posts/YC3ArwKM8xhNjYqQK/on-things-that-are-awesome"}, "n": {"title": "Eliezer Yudkowsky on Intelligence Explosion-by singularitysummit-video_id D6peN9", "author": "Eliezer Yudkowsky, speaker 1", "date": "", "url": ""}, "o": {"title": "Discussion: Yudkowsky\u2019s actual accomplishments besides divulgation", "author": "Raw_Power", "date": "2011-06-25", "url": "https://www.lesswrong.com/posts/dokw8bHND9ujPrSAT/discussion-yudkowsky-s-actual-accomplishments-besides"}, "p": {"title": "AI Foom Debate", "author": "Robin Hanson, Eliezer Yudkowsky", "date": "2013-01-01", "url": ""}, "q": {"title": "The AI Does Not Hate You: Superintelligence, Rationality and the Race to Save the World", "author": "Tom Chivers", "date": "2019-06-13", "url": ""}, "r": {"title": "Yudkowsky\u2019s brain is the pinnacle of evolution", "author": "Yudkowsky_is_awesome", "date": "2015-08-24", "url": "https://www.lesswrong.com/posts/P674BMbEny8izETGh/yudkowsky-s-brain-is-the-pinnacle-of-evolution"}}}