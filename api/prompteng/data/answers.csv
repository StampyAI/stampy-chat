"I'm not convinced, why is this important?","The importance of a topic or argument can be subjective and vary from person to person. However, there are a few general points to consider when evaluating the importance of a particular issue.

Firstly, it's important to assess the evidence and arguments surrounding the topic. Understanding the available evidence and the reasoning behind it can help determine the significance of the issue at hand. This involves considering the quality and quantity of evidence, as well as the strength of the arguments presented [b, f].

Secondly, the potential consequences or impact of the topic can contribute to its importance. For instance, if the subject matter has the potential to significantly affect individuals, society, or the future, it may be considered important [c, g].

Additionally, the expertise and credibility of those advocating for the importance of the topic can play a role. Evaluating the track record and reputation of individuals or organizations involved can provide insights into the validity of their claims [c].

It's worth noting that different people may have different perspectives on what they consider important. Personal values, interests, and priorities can influence one's assessment of the significance of a particular issue. Therefore, it's essential to engage in open-minded exploration and consider multiple viewpoints when evaluating the importance of a topic [a, d, e, h]."
a,I Really Don’t Understand Eliezer Yudkowsky’s Position on Consciousness --- Jemist --- 2021-10-29 --- https://www.lesswrong.com/posts/KFbGbTEtHiJnXw5sk/i-really-don-t-understand-eliezer-yudkowsky-s-position-on
b,"Conjunction Controversy (Or, How They Nail It Down) --- Eliezer Yudkowsky --- 2007-09-20 --- https://www.lesswrong.com/posts/cXzTpSiCrNGzeoRAz/conjunction-controversy-or-how-they-nail-it-down"
c,AIRCS Workshop: How I failed to be recruited at MIRI. --- ArthurRainbow --- 2020-01-07 --- https://www.lesswrong.com/posts/EYhWxoaCK2YSpTei9/aircs-workshop-how-i-failed-to-be-recruited-at-miri
d,Is voting theory important? An attempt to check my bias. --- Jameson Quinn --- 2019-02-17 --- https://www.lesswrong.com/posts/Bb7AYRypzpY7GYkdH/is-voting-theory-important-an-attempt-to-check-my-bias
e,Mana --- Ziz --- 2017-12-20 --- https://www.lesswrong.com/posts/39aKPedxHYEfusDWo/mana
f,Rationality when Insulated from Evidence --- JustinMElms --- 2016-06-29 --- https://www.lesswrong.com/posts/huz9YXsQK9cCBc6m8/rationality-when-insulated-from-evidence
g,Are we living at the hinge of history? --- William MacAskill
h,Swimming in Reasons --- steven0461 --- 2010-04-10 --- https://www.lesswrong.com/posts/Px662ScmbiG6BhF5R/swimming-in-reasons
i,"AI Foom Debate --- Robin Hanson, Eliezer Yudkowsky --- 2013-01-01"
"What are ""scaling laws"" and how are they relevant to safety?","Scaling laws refer to the relationship between the performance of a model and its size or resources, such as data, compute, or parameters [b]. In the context of AI, scaling laws have been observed in various domains, including image recognition and language models [c]. For example, in image recognition, increasing the size of a model by an order of magnitude may result in a decrease in accuracy by a certain fraction [c]. These scaling laws provide insights into how performance scales with resources and can help researchers extrapolate the behavior of large, expensive models without explicitly training them [b].

Scaling laws are relevant to safety because they can inform our understanding of how AI systems might behave as they become more capable and larger in scale. By studying scaling laws, researchers can gain insights into the potential risks and challenges associated with the development and deployment of advanced AI systems [a]. Understanding the relationship between model size, compute, and performance can help identify potential safety concerns and guide the development of safety measures [d]. Moreover, improving the scaling laws of safety relative to capabilities is an important objective of AI safety research [a]. By investing in multiple researchers who can potentially produce breakthroughs in scaling laws, we can enhance safety as AI systems continue to advance [a].

In summary, scaling laws describe the relationship between the performance of AI models and their size or resources. They are relevant to safety as they provide insights into how AI systems might behave as they scale up, helping researchers identify risks and develop safety measures [a, b, c, d]."
a,Perform Tractable Research While Avoiding Capabilities Externalities [Pragmatic AI Safety #4] --- Dan Hendrycks --- 2022-05-30 --- https://www.lesswrong.com/posts/dfRtxWcFDupfWpLQo/perform-tractable-research-while-avoiding-capabilities
b,Scaling Scaling Laws with Board Games --- Andy L. Jones --- 2021-04-07 --- http://arxiv.org/abs/2104.03113v2
c,"Andy Jones - AI Safety and the Scaling Hypothesis-by Towards Data Science-video_ --- Andy Jones, Jeremie Harris"
d,"Explaining Neural Scaling Laws --- Yasaman Bahri, Ethan Dyer, Jared Kaplan, Jaehoon Lee, Utkarsh Sharma --- 2021-02-12 --- http://arxiv.org/abs/2102.06701v1"
e,"Scaling Laws for Neural Language Models --- Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin Chess, Rewon Child, Scott Gray, A --- 2020-01-23 --- http://arxiv.org/abs/2001.08361v1"
f,[AN #140]: Theoretical models that predict scaling laws --- Rohin Shah --- 2021-03-04 --- https://www.lesswrong.com/posts/Yt5wAXMc7D2zLpQqx/an-140-theoretical-models-that-predict-scaling-laws
"What does the term ""x-risk"" mean?","The term ""x-risk"" refers to existential risk, which is the risk of an event or scenario that could permanently and drastically curtail the potential of Earth-originating intelligent life [b]. Existential risks are typically low-probability, high-consequence risks that have the potential to cause exceptional damage [c]. These risks can include a wide range of scenarios, such as global pandemics, nuclear war, or the development of advanced artificial general intelligence (AGI) that is not aligned with human values [d]. X-risk can also encompass the concept of s-risks, which are risks of creating intense suffering on an astronomical scale in the future [b]. Overall, x-risk refers to risks that pose a significant threat to the long-term survival and well-being of humanity [a]."
a,The value of x-risk reduction --- NathanBarnard --- 2022-05-22 --- https://www.lesswrong.com/posts/D5vuhTCdG6RN3Eu2o/the-value-of-x-risk-reduction
b,S-risks --- eFish --- https://greaterwrong.com/tag/risks-of-astronomical-suffering-s-risks?showPostCount=true&useTagName=false
c,"Member of the National Expert Panel on Climate Change and National Foreign Policy Advisory Committee --- Dennis Pamlin, Stuart Armstrong, Nick Beckstead, Kennette Benedict, Oliver Bettis, Eric Drexler, Mad"
d,Existential Risk Prevention as Global Priority --- Nick Bostrom --- 10.1111/1758-5899.12002
e,"Probing the improbable: methodological challenges for risks with low probabilities and high stakes --- Toby Ord, Rafaela Hillerbrand, Anders Sandberg, Francis Sgm --- 10.1080/13669870903126267"
f,We’re in danger. I must tell the others... --- AllanCrossman --- 2009-10-13 --- https://www.lesswrong.com/posts/MEyqjpSFogiEaoixn/we-re-in-danger-i-must-tell-the-others
g,The Precipice --- Toby Ord --- 2020-03-24
